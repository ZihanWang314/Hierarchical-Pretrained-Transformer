{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import Tokenizer\n",
    "inputs = torch.load('../condqa_old/data/dev_inputs', map_location='cpu')\n",
    "tokenizer = Tokenizer('../condqa_old/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TxtNode, get_level\n",
    "import pickle\n",
    "from functools import reduce\n",
    "import numpy\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "\n",
    "def split_tokens(tokens):\n",
    "    tokens = tokens.tolist()\n",
    "    cutoffs = []\n",
    "    current_cutoff = []\n",
    "    for idx, i in enumerate(tokens):\n",
    "        if i not in range(50265, 50272):\n",
    "            current_cutoff.append((i, idx))\n",
    "        else:\n",
    "            cutoffs.append(current_cutoff)\n",
    "            current_cutoff = [(i, idx)]\n",
    "    cutoffs.append(current_cutoff)\n",
    "    return cutoffs\n",
    "\n",
    "def create_node_from_document(document_tokens):\n",
    "    base_node = TxtNode([(0, -1)], tokenizer)\n",
    "    nodes = [base_node]\n",
    "    current_node = base_node\n",
    "    for segment in document_tokens:\n",
    "        while current_node.level >= get_level(segment):\n",
    "            current_node = current_node.parent\n",
    "\n",
    "        child = TxtNode(segment, tokenizer)\n",
    "        nodes.append(child)\n",
    "        current_node.children.append(child)\n",
    "        child.parent = current_node\n",
    "        current_node = child\n",
    "    return base_node\n",
    "\n",
    "def get_grouped_tokens(input_ids):\n",
    "    splited_tokens = split_tokens(input_ids)\n",
    "    start_tokens = splited_tokens[0]\n",
    "    document_tokens = splited_tokens[1:-1]\n",
    "    end_tokens = [i for i in splited_tokens[-1] if i[0] != 0]\n",
    "    l_document_tokens = []\n",
    "    while True:\n",
    "        token = end_tokens.pop(0)\n",
    "        if token[0] in list(range(50272, 50279)):\n",
    "            l_document_tokens.append(token)\n",
    "            break\n",
    "        else:\n",
    "            l_document_tokens.append(token)\n",
    "    document_tokens.append(l_document_tokens)\n",
    "    return start_tokens, document_tokens, end_tokens\n",
    "\n",
    "\n",
    "def repeat_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    nodes = [node for node in nodes if node.parent != None]\n",
    "    node = random.choice(nodes)\n",
    "    node_new = node.copy()\n",
    "    parent = node.parent\n",
    "    node_new.parent = parent\n",
    "    position = random.choice(list(range(len(parent.children) + 1)))\n",
    "    parent.children = parent.children[:position] + [node_new] + parent.children[position:]\n",
    "    return base_node\n",
    "\n",
    "def remove_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    nodes = [node for node in nodes if node.parent != None]\n",
    "    node = random.choice(nodes)\n",
    "    parent = node.parent\n",
    "    parent.children.remove(node)\n",
    "    return base_node\n",
    "\n",
    "def mask_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    node = random.choice(nodes)\n",
    "    node.text = [(50264, j) for i, j in node.text]\n",
    "    return base_node\n",
    "\n",
    "def reorder_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    nodes = [node for node in nodes if len(node.children) > 1]\n",
    "    node = random.choice(nodes)\n",
    "    random.shuffle(node.children)\n",
    "    return base_node\n",
    "\n",
    "\n",
    "\n",
    "def recover_index_from_node(node):\n",
    "    nodes = node.get_nodes_list()\n",
    "    text = [i.text for i in nodes][1:]\n",
    "    origin_HTMLelement_index = [i[0][1] for i in text]\n",
    "    text_lengths = [len(i) for i in text]\n",
    "    generated_HTMLelement_index = [0] + numpy.cumsum(text_lengths)[:-1].tolist()\n",
    "    HTMLelement_index = list(zip(origin_HTMLelement_index, generated_HTMLelement_index))\n",
    "    text = reduce(lambda x, y: x + y, text)\n",
    "    return text, HTMLelement_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def contrastive_sampling(input_ids):\n",
    "    start_tokens, document_tokens, end_tokens = get_grouped_tokens(input_ids)\n",
    "    base_node = create_node_from_document(document_tokens)\n",
    "    for i in range(len(base_node.get_nodes_list()) // 20):\n",
    "        base_node = repeat_a_node(base_node)\n",
    "\n",
    "    for i in range(len(base_node.get_nodes_list()) // 20):\n",
    "        base_node = remove_a_node(base_node)\n",
    "\n",
    "    for i in range(len(base_node.get_nodes_list()) // 5):\n",
    "        base_node = reorder_a_node(base_node)\n",
    "\n",
    "    for i in range(len(base_node.get_nodes_list()) // 10):\n",
    "        base_node = mask_a_node(base_node)\n",
    "\n",
    "    document_tokens, HTMLelement_index = recover_index_from_node(base_node)\n",
    "    HTMLelement_index = torch.tensor(HTMLelement_index)\n",
    "    document_tokens = start_tokens + document_tokens + end_tokens\n",
    "    HTMLelement_index[:, 1] += len(start_tokens)\n",
    "\n",
    "    return document_tokens, HTMLelement_index\n",
    "\n",
    "def generate_contrastive_sample(input):\n",
    "    sample = inputs[0]\n",
    "    input_ids = sample[0]\n",
    "    global_mask = sample[1]\n",
    "    attention_mask = sample[2]\n",
    "    mask_HTMLelements = sample[3]\n",
    "    mask_label_HTMLelements = sample[4]\n",
    "    mask_answer_span = sample[5]\n",
    "    qa_id = sample[6]\n",
    "    mask_label_condition = sample[7]\n",
    "\n",
    "    new_input, contrastive_pairs = contrastive_sampling(input_ids)\n",
    "    new_input_ids = torch.tensor([i[0] for i in new_input])\n",
    "    arrangement_index = torch.tensor([i[1] for i in new_input])\n",
    "\n",
    "    global_mask = global_mask[arrangement_index]\n",
    "    attention_mask = attention_mask[arrangement_index]\n",
    "    mask_HTMLelements = mask_HTMLelements[arrangement_index]\n",
    "    mask_label_HTMLelements = mask_label_HTMLelements[arrangement_index]\n",
    "    mask_answer_span = mask_answer_span[arrangement_index]\n",
    "    mask_label_condition = mask_label_condition[arrangement_index]\n",
    "\n",
    "    text_length = new_input_ids.shape[0]\n",
    "    new_input_ids = torch.concat((new_input_ids, torch.ones(4000 - text_length, dtype = torch.long)))\n",
    "    global_mask = torch.concat((global_mask, torch.zeros(4000 - text_length, dtype = torch.bool)))\n",
    "    attention_mask = torch.concat((attention_mask, torch.zeros(4000 - text_length, dtype = torch.bool)))\n",
    "    mask_HTMLelements = torch.concat((mask_HTMLelements, torch.zeros(4000 - text_length, dtype = torch.bool)))\n",
    "    mask_label_HTMLelements = torch.concat((mask_label_HTMLelements, torch.zeros((4000 - text_length, 3), dtype = torch.long)))\n",
    "    mask_answer_span = torch.concat((mask_answer_span, torch.zeros((4000 - text_length, 2), dtype = torch.long)))\n",
    "    mask_label_condition = torch.concat((mask_label_condition, torch.zeros((4000 - text_length, 5, 2), dtype = torch.bool)))\n",
    "\n",
    "    new_sample = [new_input_ids, global_mask, attention_mask, mask_HTMLelements, mask_label_HTMLelements, \\\n",
    "        mask_answer_span, qa_id, mask_label_condition]\n",
    "    return new_sample, contrastive_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = inputs[0]\n",
    "B, pair = generate_contrastive_sample(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_HTML_num = 3\n",
    "ans_indicator = torch.tensor(\n",
    "    [[[0, 1], [0, 0], [0, 0]]]\n",
    ")\n",
    "\n",
    "cond_indicator = torch.tensor(\n",
    "    [[[1, 0], [1, 1], [0, 0]]]\n",
    ")\n",
    "ans_indicator = ans_indicator.transpose(-2, -1)\n",
    "cond_indicator = cond_indicator.transpose(-2, -1)\n",
    "cond_indicator = cond_indicator.unsqueeze(2).repeat(1, 1, max_HTML_num, 1)# 1, 2, 3, 3\n",
    "label_condition = torch.einsum('abcd,abc->acd',cond_indicator, ans_indicator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1],\n",
       "         [1, 0, 1],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_indicator = torch.tensor([[[1, 0, 0], [0, 0, 1]], [[0, 1, 0], [1, 0, 0]]])#1, 2, 3\n",
    "cond_indicator = torch.tensor([[[0, 1, 1], [1, 1, 0]], [[1, 1, 1], [0, 0, 0]]])\n",
    "cond_indicator = cond_indicator.unsqueeze(2).repeat(1, 1, 3, 1)# 1, 2, 3, 3\n",
    "cond_indicator = torch.einsum('abcd,abc->acd',cond_indicator, ans_indicator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_mask = torch.ones(2, 3, 3, dtype=torch.long)\n",
    "original_mask = original_mask.unsqueeze(2).repeat(1, 1, ans_indicator.shape[1], 1)\n",
    "fixed_mask = torch.einsum('abcd,acd->adb', original_mask, ans_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [0, 0, 0],\n",
       "         [1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 0],\n",
       "         [1, 1, 0],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 1, 0]])\n",
    "torch.einsum('ab,ac->abc',A, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 1, 2, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print([i['has_answer'] for i in examples[25]['document'] if i['has_answer'] != -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1.0, 0.0, 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(inputs[6][5].flatten().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[6][7][inputs[6][7]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(inputs)):\n",
    "    for j in [1, 2, 3, 7]:\n",
    "        inputs[i][j] = inputs[i][j].bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ReIndexer\n",
    "indexer = ReIndexer()\n",
    "hiddens = torch.arange(40).reshape(2, 10, 2)\n",
    "mask = torch.rand(2, 10) > 0.8\n",
    "mask = mask.float()\n",
    "indexer.set_index(mask)\n",
    "new_hiddens, new_mask = indexer.re_index(hiddens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 1, 2, 3, 5, 6, 7, 8, 9],\n",
       "        [1, 5, 0, 2, 3, 4, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recovered_hiddens = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_hiddens = torch.empty_like(first_indexer.index.unsqueeze(-1).repeat(1, 1, 2)).scatter_(dim=1, index=first_indexer.index.unsqueeze(-1).repeat(1, 1, 2), src=new_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checking long example..: 100%|██████████| 285/285 [00:00<00:00, 60223.52it/s]\n",
      "converting examples to inputs..: 100%|██████████| 352/352 [00:01<00:00, 182.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_examples_to_inputs, Tokenizer\n",
    "tokenizer = Tokenizer('../condqa_old/model')\n",
    "inputs = convert_examples_to_inputs(examples, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(inputs, '../condqa_old/data/dev_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.Size([4000])\n",
      "torch.bool torch.Size([4000])\n",
      "torch.bool torch.Size([4000])\n",
      "torch.bool torch.Size([4000])\n",
      "torch.float32 torch.Size([4000, 3])\n",
      "torch.float32 torch.Size([4000, 2])\n",
      "torch.int64 torch.Size([])\n",
      "torch.bool torch.Size([4000, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "for i in inputs[0]:\n",
    "    print(i.dtype, i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.load('../condqa_old/data/dev_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[38][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 969,    0,    1],\n",
       "        [1142,    0,    0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[39][-1].nonzero()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24ed5096eae9d1d51f3453e07736a83aafded0970b93f89b73ef375a69b11d68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
