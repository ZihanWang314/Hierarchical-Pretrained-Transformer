{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.modelling_hpt import HierarchicalTransformerAttention\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "config = Config()\n",
    "config.model_hidden_size = 8\n",
    "config.ha_num_heads = 2\n",
    "config.ha_hidden_size = 4\n",
    "model = HierarchicalTransformerAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5522, 0.3920, 0.0612, 0.0100, 0.7119, 0.2532, 0.5933, 0.2496])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0,357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6140, 0.5035, 0.1051,  ..., 0.4855, 0.2005, 0.3058],\n",
       "         [0.8612, 0.0510, 0.4049,  ..., 0.3168, 0.2754, 0.6938],\n",
       "         [0.6386, 0.5630, 0.0390,  ..., 0.2994, 0.6083, 0.9945],\n",
       "         ...,\n",
       "         [0.4540, 0.1962, 0.2060,  ..., 0.3976, 0.5115, 0.8663],\n",
       "         [0.0926, 0.2572, 0.7409,  ..., 0.5588, 0.4912, 0.8088],\n",
       "         [0.7868, 0.7610, 0.6261,  ..., 0.4590, 0.2714, 0.4650]]],\n",
       "       grad_fn=<ScatterBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "hidden_states = torch.rand(1, 1000, 8)\n",
    "level_hierarchy = torch.zeros(1, 1000, dtype=torch.long)\n",
    "level_hierarchy[0,357] = 1\n",
    "level_hierarchy[0,340] = 1\n",
    "level_hierarchy[0,422] = 2\n",
    "level_hierarchy[0,365] = 2\n",
    "level_hierarchy[0,112] = 3\n",
    "level_hierarchy[0,489] = 3\n",
    "model(hidden_states, level_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "num_attn_heads = 2\n",
    "embedding = nn.Embedding(14, num_attn_heads)\n",
    "input = torch.tensor([[1, 3, 2, 1, 0], [3, 3, 1, 0, 0]])\n",
    "nan = torch.nan\n",
    "relationship_unmasked = input.unsqueeze(1) - input.unsqueeze(2)\n",
    "mask = torch.tensor([[1, 1, 1, 1, 0], [1, 1, 1, 0, 0]])\n",
    "mask = torch.einsum('ab,ac->abc', mask, mask)\n",
    "relationship = relationship_unmasked - (1 - mask) * 1000\n",
    "relationship += 6\n",
    "relationship = torch.where(relationship > 0, relationship, 0)\n",
    "batch_size, max_num_heads = relationship.shape[0], relationship.shape[1]\n",
    "relationship = embedding(relationship.flatten()).reshape(batch_size, max_num_heads, max_num_heads, num_attn_heads)\n",
    "relationship.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.modelling_hpt import HierarchicalTransformer\n",
    "from utils import Tokenizer\n",
    "\n",
    "model = HierarchicalTransformer()\n",
    "tokenizer = Tokenizer('../condqa_files/model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(['<h1>want to say goodbye']).unsqueeze(0).cuda()\n",
    "attn_masks = torch.tensor([[1, 1, 1, 1, 0]]).cuda()\n",
    "global_masks = torch.tensor([[1, 0, 0, 1, 0]]).cuda()\n",
    "model.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768]) tensor([[[-0.0103,  0.0316, -0.0098,  ..., -0.0486,  0.0084, -0.1527],\n",
      "         [ 0.1514,  0.4159,  0.0287,  ..., -0.6583,  0.0778,  0.0291],\n",
      "         [-0.3224, -0.4276, -0.1158,  ...,  0.0882, -0.5146,  0.5798],\n",
      "         ...,\n",
      "         [-0.6967, -0.1657, -0.2636,  ..., -0.2160, -0.0507, -0.0555],\n",
      "         [-0.6967, -0.1657, -0.2636,  ..., -0.2160, -0.0507, -0.0555],\n",
      "         [-0.6967, -0.1657, -0.2636,  ..., -0.2160, -0.0507, -0.0555]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[ 4.8578e-02,  2.8375e-02, -1.9885e-03,  ..., -1.7267e-04,\n",
      "          -2.2234e-03, -5.7610e-02],\n",
      "         [ 3.2383e-01,  4.8041e-01, -1.7935e-01,  ..., -5.3644e-01,\n",
      "           4.4969e-02,  4.5482e-01],\n",
      "         [-6.9267e-02, -3.5137e-01, -3.0398e-01,  ...,  1.1198e-01,\n",
      "          -3.4803e-01,  5.2847e-01],\n",
      "         ...,\n",
      "         [ 6.3892e-02, -7.6392e-02, -1.2592e-01,  ..., -2.5100e-01,\n",
      "           5.1669e-02,  3.1363e-01],\n",
      "         [ 6.3892e-02, -7.6392e-02, -1.2592e-01,  ..., -2.5100e-01,\n",
      "           5.1669e-02,  3.1363e-01],\n",
      "         [ 6.3892e-02, -7.6392e-02, -1.2592e-01,  ..., -2.5100e-01,\n",
      "           5.1669e-02,  3.1363e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[ 0.0533,  0.0241, -0.0491,  ...,  0.0251,  0.0134,  0.0656],\n",
      "         [ 0.2808, -0.0168, -0.0020,  ..., -0.4087, -0.3474,  0.2211],\n",
      "         [-0.2398, -0.3783, -0.6959,  ...,  0.1953, -0.6417,  0.1945],\n",
      "         ...,\n",
      "         [ 0.2342,  0.1654, -0.0929,  ...,  0.3204,  0.5037,  0.2068],\n",
      "         [ 0.2342,  0.1654, -0.0929,  ...,  0.3204,  0.5037,  0.2068],\n",
      "         [ 0.2342,  0.1654, -0.0929,  ...,  0.3204,  0.5037,  0.2068]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[ 0.0271,  0.0699, -0.0148,  ..., -0.0118, -0.0673, -0.0212],\n",
      "         [-0.0294, -0.0284,  0.0252,  ..., -0.1006, -0.7259, -0.5756],\n",
      "         [-0.4721, -0.4596, -0.6915,  ...,  0.2363, -0.2447,  0.0889],\n",
      "         ...,\n",
      "         [ 0.0949,  0.3826,  0.8811,  ..., -0.0983,  0.0700,  0.4613],\n",
      "         [ 0.0949,  0.3826,  0.8811,  ..., -0.0983,  0.0700,  0.4613],\n",
      "         [ 0.0949,  0.3826,  0.8811,  ..., -0.0983,  0.0700,  0.4613]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[-0.0096,  0.0889,  0.0382,  ..., -0.0596,  0.1308,  0.0227],\n",
      "         [-0.6045, -0.2236, -0.2008,  ..., -0.1058, -0.4017, -0.9843],\n",
      "         [-0.4199, -0.4886, -0.7853,  ...,  0.3218, -0.0951, -0.4332],\n",
      "         ...,\n",
      "         [-0.0564, -0.2139, -0.9085,  ...,  0.3034,  0.4397,  0.2000],\n",
      "         [-0.0564, -0.2139, -0.9085,  ...,  0.3034,  0.4397,  0.2000],\n",
      "         [-0.0564, -0.2139, -0.9085,  ...,  0.3034,  0.4397,  0.2000]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[ 0.1081,  0.2734,  0.2428,  ..., -0.0720, -0.0298, -0.0526],\n",
      "         [ 0.0472, -0.1094, -0.0099,  ..., -0.4087,  0.0749, -0.9695],\n",
      "         [-0.4002, -0.6066, -0.5237,  ..., -0.0272,  0.4096, -0.7996],\n",
      "         ...,\n",
      "         [-0.2856, -0.0667,  0.1310,  ..., -0.1170,  0.2120, -0.4122],\n",
      "         [-0.2856, -0.0667,  0.1310,  ..., -0.1170,  0.2120, -0.4122],\n",
      "         [-0.2856, -0.0667,  0.1310,  ..., -0.1170,  0.2120, -0.4122]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[-0.0610,  0.1999, -0.0414,  ...,  0.0368,  0.0101,  0.0099],\n",
      "         [-0.0917, -0.2894, -0.2141,  ..., -0.1877,  0.1603, -0.5257],\n",
      "         [ 0.2035, -0.3285, -0.4493,  ...,  0.0298,  0.3364, -0.3138],\n",
      "         ...,\n",
      "         [ 0.3489, -0.1448, -0.0839,  ..., -0.1994, -0.2813,  0.0884],\n",
      "         [ 0.3489, -0.1448, -0.0839,  ..., -0.1994, -0.2813,  0.0884],\n",
      "         [ 0.3489, -0.1448, -0.0839,  ..., -0.1994, -0.2813,  0.0884]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[-3.1622e-01,  3.6663e-01, -4.9302e-04,  ...,  1.0138e-01,\n",
      "          -6.6105e-02, -1.2147e-01],\n",
      "         [-2.3728e-01, -4.2540e-01,  2.5929e-02,  ..., -5.5214e-02,\n",
      "          -6.4816e-01, -7.9213e-01],\n",
      "         [-1.8319e-01, -3.0834e-01, -2.9911e-01,  ...,  2.5479e-01,\n",
      "          -2.8900e-01, -8.1999e-01],\n",
      "         ...,\n",
      "         [ 1.0301e-01,  5.9317e-04, -1.1047e-01,  ..., -6.7932e-02,\n",
      "          -1.8348e-02, -1.4624e-02],\n",
      "         [ 1.0301e-01,  5.9317e-04, -1.1047e-01,  ..., -6.7932e-02,\n",
      "          -1.8348e-02, -1.4624e-02],\n",
      "         [ 1.0301e-01,  5.9317e-04, -1.1047e-01,  ..., -6.7932e-02,\n",
      "          -1.8348e-02, -1.4624e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[-0.1828,  0.0495, -0.0377,  ...,  0.0391,  0.1378, -0.1491],\n",
      "         [-0.4416, -0.1730, -0.0752,  ...,  0.0294, -0.6650, -1.0111],\n",
      "         [-0.3248, -0.1109, -0.2044,  ...,  0.2002, -0.1736, -0.4569],\n",
      "         ...,\n",
      "         [ 0.0391,  0.0564,  0.3104,  ..., -0.0765,  0.2428, -0.3055],\n",
      "         [ 0.0391,  0.0564,  0.3104,  ..., -0.0765,  0.2428, -0.3055],\n",
      "         [ 0.0391,  0.0564,  0.3104,  ..., -0.0765,  0.2428, -0.3055]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[-1.3480e-01,  7.0335e-02, -3.4070e-02,  ...,  4.7136e-05,\n",
      "           3.4240e-02, -1.1445e-02],\n",
      "         [-4.5905e-01, -2.5723e-01,  1.5017e-01,  ..., -1.1622e-01,\n",
      "          -5.0954e-02, -5.1082e-01],\n",
      "         [-2.6824e-02, -1.7451e-01, -1.4652e-02,  ...,  1.8824e-01,\n",
      "          -7.8392e-02, -2.5820e-01],\n",
      "         ...,\n",
      "         [-1.2695e-01,  3.5375e-02, -2.0502e-02,  ...,  9.5696e-03,\n",
      "           2.7802e-02, -8.7591e-02],\n",
      "         [-1.2695e-01,  3.5375e-02, -2.0502e-02,  ...,  9.5696e-03,\n",
      "           2.7802e-02, -8.7591e-02],\n",
      "         [-1.2695e-01,  3.5375e-02, -2.0502e-02,  ...,  9.5696e-03,\n",
      "           2.7802e-02, -8.7591e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[-0.0510, -0.0168,  0.0266,  ...,  0.0608, -0.0067,  0.0154],\n",
      "         [-0.5072, -0.2554, -0.1135,  ...,  0.0450,  0.1353, -0.4445],\n",
      "         [ 0.0348, -0.3779, -0.2556,  ...,  0.2482, -0.0154, -0.2009],\n",
      "         ...,\n",
      "         [-0.0824,  0.0518,  0.0456,  ...,  0.0182, -0.0025, -0.0865],\n",
      "         [-0.0824,  0.0518,  0.0456,  ...,  0.0182, -0.0025, -0.0865],\n",
      "         [-0.0824,  0.0518,  0.0456,  ...,  0.0182, -0.0025, -0.0865]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 512, 768]) tensor([[[-0.0747,  0.0752, -0.0151,  ..., -0.1622, -0.0339, -0.0404],\n",
      "         [-0.1478,  0.0336, -0.0080,  ..., -0.1127,  0.0643, -0.1872],\n",
      "         [ 0.1026, -0.0994,  0.0026,  ..., -0.2137, -0.0058, -0.1224],\n",
      "         ...,\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745],\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745],\n",
      "         [-0.0236,  0.0741, -0.0145,  ..., -0.0990, -0.0409, -0.0745]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0747,  0.0752, -0.0151,  ..., -0.1622, -0.0339, -0.0404],\n",
       "        [-0.1478,  0.0336, -0.0080,  ..., -0.1127,  0.0643, -0.1872],\n",
       "        [ 0.1026, -0.0994,  0.0026,  ..., -0.2137, -0.0058, -0.1224],\n",
       "        [-0.0172,  0.0057,  0.0860,  ..., -0.2074,  0.0802, -0.0208],\n",
       "        [ 0.0434,  0.1687, -0.3759,  ..., -0.2970, -0.1433,  0.0217]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, attn_masks, global_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.load('../condqa_files/data/train_inputs', map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 5, 2])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]['labels'][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "attention = nn.MultiheadAttention(24, 3, 0.1, batch_first=True)\n",
    "hidden_states = torch.ones(1, 5, 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517]]], grad_fn=<TransposeBackward0>), tensor([[[0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000]]], grad_fn=<DivBackward0>))\n",
      "(tensor([[[ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517],\n",
      "         [ 0.2209,  0.4147, -0.4436, -0.0619, -0.1164,  0.4118,  0.3615,\n",
      "           0.3154, -0.5760, -0.3446, -0.7165,  0.6312,  0.0609,  0.0439,\n",
      "           0.4782, -0.2106, -0.1674,  0.1571, -0.2756, -0.4135, -0.8233,\n",
      "          -0.4418,  0.3761, -0.3517]]], grad_fn=<TransposeBackward0>), tensor([[[0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000]]], grad_fn=<DivBackward0>))\n"
     ]
    }
   ],
   "source": [
    "hidden_states[0, -1, :] = 1\n",
    "A = attention(hidden_states, hidden_states, hidden_states, key_padding_mask = torch.tensor([[False, False, False, False, True]]), )\n",
    "print(A)\n",
    "hidden_states[0, -1, :] = 2\n",
    "A = attention(hidden_states, hidden_states, hidden_states, key_padding_mask = torch.tensor([[False, False, False, False, True]]), )\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TxtNode, get_level\n",
    "import pickle\n",
    "from functools import reduce\n",
    "import numpy\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "\n",
    "def split_tokens(tokens):\n",
    "    tokens = tokens.tolist()\n",
    "    cutoffs = []\n",
    "    current_cutoff = []\n",
    "    for idx, i in enumerate(tokens):\n",
    "        if i not in range(50265, 50272):\n",
    "            current_cutoff.append((i, idx))\n",
    "        else:\n",
    "            cutoffs.append(current_cutoff)\n",
    "            current_cutoff = [(i, idx)]\n",
    "    cutoffs.append(current_cutoff)\n",
    "    return cutoffs\n",
    "\n",
    "def create_node_from_document(document_tokens):\n",
    "    base_node = TxtNode([(0, -1)], tokenizer)\n",
    "    nodes = [base_node]\n",
    "    current_node = base_node\n",
    "    for segment in document_tokens:\n",
    "        while current_node.level >= get_level(segment):\n",
    "            current_node = current_node.parent\n",
    "\n",
    "        child = TxtNode(segment, tokenizer)\n",
    "        nodes.append(child)\n",
    "        current_node.children.append(child)\n",
    "        child.parent = current_node\n",
    "        current_node = child\n",
    "    return base_node\n",
    "\n",
    "def get_grouped_tokens(input_ids):\n",
    "    splited_tokens = split_tokens(input_ids)\n",
    "    start_tokens = splited_tokens[0]\n",
    "    document_tokens = splited_tokens[1:-1]\n",
    "    end_tokens = [i for i in splited_tokens[-1] if i[0] != 0]\n",
    "    l_document_tokens = []\n",
    "    while True:\n",
    "        token = end_tokens.pop(0)\n",
    "        if token[0] in list(range(50272, 50279)):\n",
    "            l_document_tokens.append(token)\n",
    "            break\n",
    "        else:\n",
    "            l_document_tokens.append(token)\n",
    "    document_tokens.append(l_document_tokens)\n",
    "    return start_tokens, document_tokens, end_tokens\n",
    "\n",
    "\n",
    "def repeat_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    nodes = [node for node in nodes if node.parent != None]\n",
    "    node = random.choice(nodes)\n",
    "    node_new = node.copy()\n",
    "    parent = node.parent\n",
    "    node_new.parent = parent\n",
    "    position = random.choice(list(range(len(parent.children) + 1)))\n",
    "    parent.children = parent.children[:position] + [node_new] + parent.children[position:]\n",
    "    return base_node\n",
    "\n",
    "def remove_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    nodes = [node for node in nodes if node.parent != None]\n",
    "    node = random.choice(nodes)\n",
    "    parent = node.parent\n",
    "    parent.children.remove(node)\n",
    "    return base_node\n",
    "\n",
    "def mask_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    node = random.choice(nodes)\n",
    "    node.text = [(50264, j) for i, j in node.text]\n",
    "    return base_node\n",
    "\n",
    "def reorder_a_node(base_node):\n",
    "    nodes = base_node.get_nodes_list()\n",
    "    nodes = [node for node in nodes if len(node.children) > 1]\n",
    "    node = random.choice(nodes)\n",
    "    random.shuffle(node.children)\n",
    "    return base_node\n",
    "\n",
    "\n",
    "\n",
    "def recover_index_from_node(node):\n",
    "    nodes = node.get_nodes_list()\n",
    "    text = [i.text for i in nodes][1:]\n",
    "    origin_HTMLelement_index = [i[0][1] for i in text]\n",
    "    text_lengths = [len(i) for i in text]\n",
    "    generated_HTMLelement_index = [0] + numpy.cumsum(text_lengths)[:-1].tolist()\n",
    "    HTMLelement_index = list(zip(origin_HTMLelement_index, generated_HTMLelement_index))\n",
    "    text = reduce(lambda x, y: x + y, text)\n",
    "    return text, HTMLelement_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def contrastive_sampling(input_ids):\n",
    "    start_tokens, document_tokens, end_tokens = get_grouped_tokens(input_ids)\n",
    "    base_node = create_node_from_document(document_tokens)\n",
    "    for i in range(len(base_node.get_nodes_list()) // 20):\n",
    "        base_node = repeat_a_node(base_node)\n",
    "\n",
    "    for i in range(len(base_node.get_nodes_list()) // 20):\n",
    "        base_node = remove_a_node(base_node)\n",
    "\n",
    "    for i in range(len(base_node.get_nodes_list()) // 5):\n",
    "        base_node = reorder_a_node(base_node)\n",
    "\n",
    "    for i in range(len(base_node.get_nodes_list()) // 10):\n",
    "        base_node = mask_a_node(base_node)\n",
    "\n",
    "    document_tokens, HTMLelement_index = recover_index_from_node(base_node)\n",
    "    HTMLelement_index = torch.tensor(HTMLelement_index)\n",
    "    document_tokens = start_tokens + document_tokens + end_tokens\n",
    "    HTMLelement_index[:, 1] += len(start_tokens)\n",
    "\n",
    "    return document_tokens, HTMLelement_index\n",
    "\n",
    "def generate_contrastive_sample(input):\n",
    "    sample = inputs[0]\n",
    "    input_ids = sample[0]\n",
    "    global_mask = sample[1]\n",
    "    attention_mask = sample[2]\n",
    "    mask_HTMLelements = sample[3]\n",
    "    mask_label_HTMLelements = sample[4]\n",
    "    mask_answer_span = sample[5]\n",
    "    qa_id = sample[6]\n",
    "    mask_label_condition = sample[7]\n",
    "\n",
    "    new_input, contrastive_pairs = contrastive_sampling(input_ids)\n",
    "    new_input_ids = torch.tensor([i[0] for i in new_input])\n",
    "    arrangement_index = torch.tensor([i[1] for i in new_input])\n",
    "\n",
    "    global_mask = global_mask[arrangement_index]\n",
    "    attention_mask = attention_mask[arrangement_index]\n",
    "    mask_HTMLelements = mask_HTMLelements[arrangement_index]\n",
    "    mask_label_HTMLelements = mask_label_HTMLelements[arrangement_index]\n",
    "    mask_answer_span = mask_answer_span[arrangement_index]\n",
    "    mask_label_condition = mask_label_condition[arrangement_index]\n",
    "\n",
    "    text_length = new_input_ids.shape[0]\n",
    "    new_input_ids = torch.concat((new_input_ids, torch.ones(4000 - text_length, dtype = torch.long)))\n",
    "    global_mask = torch.concat((global_mask, torch.zeros(4000 - text_length, dtype = torch.bool)))\n",
    "    attention_mask = torch.concat((attention_mask, torch.zeros(4000 - text_length, dtype = torch.bool)))\n",
    "    mask_HTMLelements = torch.concat((mask_HTMLelements, torch.zeros(4000 - text_length, dtype = torch.bool)))\n",
    "    mask_label_HTMLelements = torch.concat((mask_label_HTMLelements, torch.zeros((4000 - text_length, 3), dtype = torch.long)))\n",
    "    mask_answer_span = torch.concat((mask_answer_span, torch.zeros((4000 - text_length, 2), dtype = torch.long)))\n",
    "    mask_label_condition = torch.concat((mask_label_condition, torch.zeros((4000 - text_length, 5, 2), dtype = torch.bool)))\n",
    "\n",
    "    new_sample = [new_input_ids, global_mask, attention_mask, mask_HTMLelements, mask_label_HTMLelements, \\\n",
    "        mask_answer_span, qa_id, mask_label_condition]\n",
    "    return new_sample, contrastive_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = inputs[0]\n",
    "B, pair = generate_contrastive_sample(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_HTML_num = 3\n",
    "ans_indicator = torch.tensor(\n",
    "    [[[0, 1], [0, 0], [0, 0]]]\n",
    ")\n",
    "\n",
    "cond_indicator = torch.tensor(\n",
    "    [[[1, 0], [1, 1], [0, 0]]]\n",
    ")\n",
    "ans_indicator = ans_indicator.transpose(-2, -1)\n",
    "cond_indicator = cond_indicator.transpose(-2, -1)\n",
    "cond_indicator = cond_indicator.unsqueeze(2).repeat(1, 1, max_HTML_num, 1)# 1, 2, 3, 3\n",
    "label_condition = torch.einsum('abcd,abc->acd',cond_indicator, ans_indicator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24ed5096eae9d1d51f3453e07736a83aafded0970b93f89b73ef375a69b11d68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
